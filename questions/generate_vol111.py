import json
import os

# 保存先ディレクトリ
OUTPUT_DIR = "."
INDEX_FILE = "index.json"

# ==========================================
# Vol.111 新規問題データ定義
# ==========================================

# 1. 第3章 AI/ML (ch3_ai_vol111.json)
q3_ai = [
    {
        "id": "Q3-AI-V111-01",
        "chapter": "第3章",
        "level": "K4",
        "category": "AI/ML",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【分析】本番運用中のAIモデル劣化（Model Drift）。\nリリース当初は高精度だった「需要予測AI」が、半年経過して予測精度が著しく低下した。\nプログラムの変更は行っていない。\nこの現象の原因を特定し、対策するためのアクションとして最も適切なものはどれか。",
        "options": [
            "AIのプログラムコードが経年劣化で破損した可能性があるため、ソースコードを全行レビューし、バグが混入していないかを確認する（ソフトウェアは物理的に劣化しない）",
            "市場環境の変化により、入力データ（推論データ）の分布が学習時と乖離した「データドリフト（Data Drift）」を疑い、直近のデータを用いてモデルを再学習（Retrain）させる",
            "予測精度が落ちたのは一時的なノイズである可能性が高いため、特に対策は行わず、さらに半年ほど様子を見て自然に回復するのを待つ（放置リスク）",
            "AIモデルのアーキテクチャ自体が古くなったため、現在稼働中のモデルを破棄し、最新のよりパラメータ数の多い大規模モデルに置き換える（原因分析なしの刷新）"
        ],
        "answer": [
            "市場環境の変化により、入力データ（推論データ）の分布が学習時と乖離した「データドリフト（Data Drift）」を疑い、直近のデータを用いてモデルを再学習（Retrain）させる"
        ],
        "explanation": "【解説】\nAIモデルはコードが変わらなくても、入力データ（現実世界）の傾向が変わることで精度が落ちます（ドリフト）。対策は「モニタリング」と「再学習」です。",
        "tags": ["第3章", "AI/ML", "シナリオ", "K4"]
    }
]

# 2. 第1章 一般 (ch1_general_vol111.json)
q1_gen = [
    {
        "id": "Q1-GEN-V111-01",
        "chapter": "第1章",
        "level": "K3",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】根本原因分析（RCA）と再発防止。\n「設定ファイルの記述ミスにより本番障害が発生した」という事象に対し、担当者が「次回から気をつけます」という対策案を出してきた。\nマネージャとして、より効果的な再発防止策を導き出すための指導内容はどれか。",
        "options": [
            "個人の注意不足が根本原因であるため、担当者に対して始末書を書かせ、ペナルティを与えることで意識改革を促す（恐怖による管理は再発防止にならない）",
            "「なぜミスが起きたか」ではなく「なぜミスを検知できなかったか（プロセスの欠陥）」に着目させ、バリデーションツールの導入や自動チェックの仕組み作りを提案させる",
            "チェックリストの項目を倍に増やし、ダブルチェック（二人一組での確認）をトリプルチェック（三人確認）に強化することで、漏れを力技で防ぐ（工数増と形骸化のリスク）",
            "設定ファイルを使用する運用自体がリスクであるため、すべての設定値をハードコーディング（ソースコードに埋め込み）に変更するよう指示する（保守性の低下）"
        ],
        "answer": [
            "「なぜミスが起きたか」ではなく「なぜミスを検知できなかったか（プロセスの欠陥）」に着目させ、バリデーションツールの導入や自動チェックの仕組み作りを提案させる"
        ],
        "explanation": "【解説】\n「気をつける」は対策ではありません。ヒューマンエラーをシステムやプロセス（自動検知など）で防ぐ仕組みに変えるのがRCAのゴールです。",
        "tags": ["第1章", "一般", "シナリオ", "K3"]
    }
]

# 3. 第2章 一般 (ch2_general_vol111.json)
q2_gen = [
    {
        "id": "Q2-GEN-V111-01",
        "chapter": "第2章",
        "level": "K3",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】静的解析ツールの段階的導入（ラチェット運用）。\nレガシーコードに静的解析を導入したが、警告が数千件出ており、開発チームが修正を拒否している。\n品質を維持しつつ、現実的にツールを定着させるための運用ルールはどれか。",
        "options": [
            "数千件の警告はすべて潜在的なバグであるため、開発を一旦停止し、すべての警告を解消するまで新機能の実装を禁止する（ビジネス停止のリスク）",
            "既存のコードに対する警告は「ベースライン（現状維持）」として許容し、新しくコミットされるコード（差分）に対してのみ「警告ゼロ」を義務付ける（Clean as you go）",
            "警告が出ると開発者のモチベーションが下がるため、もっとも重大な「Crash」レベル以外のルールはすべて無効化し、警告が出ないように設定を緩める（ツールの意義喪失）",
            "解析ツールはローカル環境のみで使用することとし、CIサーバーでの自動実行は行わず、修正するかどうかは個人の判断に完全に任せる（強制力がなく定着しない）"
        ],
        "answer": [
            "既存のコードに対する警告は「ベースライン（現状維持）」として許容し、新しくコミットされるコード（差分）に対してのみ「警告ゼロ」を義務付ける（Clean as you go）"
        ],
        "explanation": "【解説】\n大量の負債を一度に返すのは不可能です。「来た時よりも美しく（Boy Scout Rule）」の精神で、新規・変更分から品質基準を適用するのが現実解です。",
        "tags": ["第2章", "一般", "シナリオ", "K3"]
    }
]

# 4. 第1章 AWS (ch1_aws_vol111.json)
q1_aws = [
    {
        "id": "Q1-AWS-V111-01",
        "chapter": "第1章",
        "level": "K3",
        "category": "AWS",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】S3データの保護と復旧テスト。\n操作ミスによるS3オブジェクトの削除や上書きからデータを保護し、かつ万が一の場合に特定バージョンに復旧できることを検証したい。\n有効にするべき機能と、その検証方法はどれか。",
        "options": [
            "S3の「バージョニング」機能を有効にし、ファイルを上書き・削除した後でも、過去のバージョンIDを指定して復元できることを実際にAPIまたはコンソールで確認する",
            "毎日S3のデータをローカルPCに全量ダウンロードしてバックアップを取り、削除時にはローカルから再アップロードする運用手順をテストする（データ量的に非現実的）",
            "S3の「サーバーアクセスログ」を有効にし、削除されたというログ記録が残っていることを確認する（ログがあってもデータ自体は復元できない）",
            "RAID構成のような冗長化オプションを探して設定し、ディスク障害が発生してもデータが消えないことを確認する（S3はデフォルトで冗長化されており、誤操作対策にはならない）"
        ],
        "answer": [
            "S3の「バージョニング」機能を有効にし、ファイルを上書き・削除した後でも、過去のバージョンIDを指定して復元できることを実際にAPIまたはコンソールで確認する"
        ],
        "explanation": "【解説】\n誤操作（論理削除・上書き）対策には「バージョニング」が必須です。テストでは実際に削除/上書きを行い、旧バージョンからのリストアを検証します。",
        "tags": ["第1章", "AWS", "シナリオ", "K3"]
    }
]

# 5. 第2章 金融 (ch2_finance_vol111.json)
q2_fin = [
    {
        "id": "Q2-FIN-V111-01",
        "chapter": "第2章",
        "level": "K4",
        "category": "金融",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【分析】利息計算における「日割計算」のテスト。\nローンの日割利息計算において、うるう年（366日）と平年（365日）の扱いに起因する計算ミスを防ぎたい。\n境界値分析に基づき、重点的にテストすべき日付パターンの組み合わせはどれか。",
        "options": [
            "平年の適当な日付（7月1日〜7月31日）と、うるう年の適当な日付（7月1日〜7月31日）を選んで計算し、結果を比較する（日数が同じ月同士では差異が出にくい）",
            "うるう年の「2月28日〜3月1日」を跨ぐ期間と、平年の「2月28日〜3月1日」を跨ぐ期間、および「年末年始（12/31〜1/1）」のケースを作成し、分母（365/366）の切り替わりを確認する",
            "1年間の全日付（365日分）をランダムにサンプリングし、エラーが出ないことを確認する（重要な境界値である2月末が選ばれない可能性がある）",
            "計算ロジックはライブラリに任せているため、アプリ側ではテストを行わず、ライブラリの仕様書を信じてテスト完了とする（統合時の設定ミスを見逃す）"
        ],
        "answer": [
            "うるう年の「2月28日〜3月1日」を跨ぐ期間と、平年の「2月28日〜3月1日」を跨ぐ期間、および「年末年始（12/31〜1/1）」のケースを作成し、分母（365/366）の切り替わりを確認する"
        ],
        "explanation": "【解説】\n日割計算の最大の鬼門は「うるう年の2/29」と「年またぎ（分母変更）」です。ここをピンポイントで狙うのが境界値分析の定石です。",
        "tags": ["第2章", "金融", "シナリオ", "K4"]
    }
]

# ==========================================
# ファイル生成 & Index更新処理
# ==========================================
files_content = {
    "ch3_ai_vol111.json": q3_ai,
    "ch1_general_vol111.json": q1_gen,
    "ch2_general_vol111.json": q2_gen,
    "ch1_aws_vol111.json": q1_aws,
    "ch2_finance_vol111.json": q2_fin
}

def generate_and_update():
    # 1. ファイル生成
    new_entries = []
    
    print("--- ファイル生成開始 ---")
    for filename, content in files_content.items():
        file_path = os.path.join(OUTPUT_DIR, filename)
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(content, f, ensure_ascii=False, indent=2)
            print(f"作成: {filename}")
            
            # メタデータ抽出（Index用）
            first_q = content[0]
            entry = {
                "path": f"questions/{filename}", # アプリの仕様に合わせたパス
                "chapter": first_q.get("chapter", "不明"),
                "category": first_q.get("category", "不明"),
                "klevel": first_q.get("level", "K2"),
                "qCount": len(content)
            }
            new_entries.append(entry)
            
        except Exception as e:
            print(f"エラー作成中 {filename}: {e}")

    # 2. Index更新
    print("\n--- Index更新開始 ---")
    if not os.path.exists(INDEX_FILE):
        print(f"エラー: {INDEX_FILE} が見つかりません。")
        return

    try:
        with open(INDEX_FILE, 'r', encoding='utf-8') as f:
            index_data = json.load(f)
        
        existing_paths = {item.get("path") for item in index_data.get("chunks", [])}
        added_count = 0
        
        for entry in new_entries:
            if entry["path"] not in existing_paths:
                index_data["chunks"].append(entry)
                print(f"Index追加: {entry['path']}")
                added_count += 1
            else:
                print(f"Indexスキップ（登録済）: {entry['path']}")
        
        if added_count > 0:
            with open(INDEX_FILE, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, ensure_ascii=False, indent=2)
            print(f"Index保存完了: {added_count}件追加")
        else:
            print("Index更新なし")

    except Exception as e:
        print(f"Index更新エラー: {e}")

if __name__ == "__main__":
    generate_and_update()