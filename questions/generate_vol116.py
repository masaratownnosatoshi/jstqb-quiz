import json
import os

# 保存先ディレクトリ
OUTPUT_DIR = "."
INDEX_FILE = "index.json"

# ==========================================
# Vol.116 新規問題データ定義
# ==========================================

# 1. 第3章 一般 (ch3_general_vol116.json)
q3_gen = [
    {
        "id": "Q3-GEN-V116-01",
        "chapter": "第3章",
        "level": "K3",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】テスト自動化における「フレイルキー（Flaky）テスト」対策。\n自動テスト実行時に「成功したり失敗したりする（不安定な）」テストケースが増えており、テスト結果の信頼性が損なわれている。\nこの問題に対する恒久的な対処法として、アンチパターンを避けつつ実施すべき対策はどれか。",
        "options": [
            "不安定なテストケースには「リトライ機能（自動再実行）」を実装し、3回実行して1回でも成功すれば合格とみなすことで、見かけ上のエラーを減らす（根本原因を隠蔽するアンチパターン）",
            "失敗した時のスクリーンショットやログを詳細に記録する仕組みを導入した上で、不安定なテストを「隔離（Quarantine）」し、原因（タイミング依存、データ残留など）を特定して修正するまでメインのパイプラインからは外す",
            "テスト環境のサーバースペックを最高レベルに引き上げ、処理速度を向上させることで、タイミング問題による失敗を力技でねじ伏せる（コスト増かつ根本解決ではない）",
            "不安定なテストは維持管理コストに見合わないため即座に削除し、その機能については今後一切テストを行わないことにする（テストカバレッジの低下）"
        ],
        "answer": [
            "失敗した時のスクリーンショットやログを詳細に記録する仕組みを導入した上で、不安定なテストを「隔離（Quarantine）」し、原因（タイミング依存、データ残留など）を特定して修正するまでメインのパイプラインからは外す"
        ],
        "explanation": "【解説】\nFlakyテストは信頼性の癌です。リトライで誤魔化すのではなく、隔離して原因を究明・修正するのが正しいアプローチです。",
        "tags": ["第3章", "一般", "シナリオ", "K3"]
    }
]

# 2. 第1章 一般 (ch1_general_vol116.json)
q1_gen = [
    {
        "id": "Q1-GEN-V116-01",
        "chapter": "第1章",
        "level": "K4",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【分析】テストカバレッジの解釈。\n単体テストのカバレッジ（C1：分岐網羅）が100%に達しているモジュールで、リリース後に重大なバグが発見された。\nカバレッジ分析の限界として、この現象を説明する最も適切な理由はどれか。",
        "options": [
            "カバレッジ計測ツールのバグであり、実際には100%網羅されていなかった可能性が高いため、別のツールで再計測すべきである（ツールのせいにしている）",
            "C1カバレッジは「実装されたロジック」の分岐を網羅したに過ぎず、「仕様として本来実装されるべきだが抜けている機能（仕様漏れ）」や「タイミング依存のバグ」は検出できない",
            "C1カバレッジでは不十分であり、より厳密な「MC/DCカバレッジ」を100%にしていれば、仕様漏れも含めて全てのバグを検出できたはずである（MC/DCでも仕様漏れは検出できない）",
            "カバレッジ100%でバグが出るということは、プログラミング言語自体の不具合（コンパイラのバグ）である可能性が高い（極めて稀なケースを一般化している）"
        ],
        "answer": [
            "C1カバレッジは「実装されたロジック」の分岐を網羅したに過ぎず、「仕様として本来実装されるべきだが抜けている機能（仕様漏れ）」や「タイミング依存のバグ」は検出できない"
        ],
        "explanation": "【解説】\nカバレッジは「書かれたコード」の網羅率であり、「書かれるべきだったコード（仕様漏れ）」が無いことは証明できません。これがカバレッジの最大の限界です。",
        "tags": ["第1章", "一般", "シナリオ", "K4"]
    }
]

# 3. 第2章 一般 (ch2_general_vol116.json)
q2_gen = [
    {
        "id": "Q2-GEN-V116-01",
        "chapter": "第2章",
        "level": "K3",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】テストデータのクレンジング（サニタイズ）。\n本番データをテスト環境に移行する際、機密情報をマスキングするツールを自作した。\nこのツールの信頼性を検証し、情報漏洩リスクがないことを保証するためのテストケースはどれか。",
        "options": [
            "マスキング後のデータを目視でランダムに確認し、なんとなく個人情報っぽくない文字列になっていることを確認する（ランダムチェックでは漏れが出る）",
            "個人情報（氏名、電話番号、メアド等）を含む既知のデータセットを入力し、出力データに元の値が一切含まれていないこと、および変換後のデータがシステムの入力規則（桁数や型）を満たしていることを全件検証する",
            "ツールを実行してエラーが出ずに終了することだけを確認し、データの中身については移行後のアプリ動作確認で代用する（セキュリティリスクの見逃し）",
            "マスキング処理のソースコードを読み、ロジックに間違いがないことを確認するだけでテスト完了とする（実装ミスやライブラリのバグを見逃す）"
        ],
        "answer": [
            "個人情報（氏名、電話番号、メアド等）を含む既知のデータセットを入力し、出力データに元の値が一切含まれていないこと、および変換後のデータがシステムの入力規則（桁数や型）を満たしていることを全件検証する"
        ],
        "explanation": "【解説】\nマスキングツールのテストでは、「秘匿性（元データが消えているか）」と「有用性（テストデータとして使える形式か）」の両面検証が必須です。",
        "tags": ["第2章", "一般", "シナリオ", "K3"]
    }
]

# 4. 第1章 AWS (ch1_aws_vol116.json)
q1_aws = [
    {
        "id": "Q1-AWS-V116-01",
        "chapter": "第1章",
        "level": "K3",
        "category": "AWS",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】DynamoDBのキャパシティ設計テスト。\nDynamoDBを使用したアプリケーションで、スパイクアクセス時（急激な負荷増）にスロットリング（Throttling）エラーが発生しないかを確認したい。\nオンデマンドモードではなくプロビジョンドモードを採用している場合、適切なテスト方法はどれか。",
        "options": [
            "JMeter等で徐々に負荷を上げていき、読み込み/書き込みキャパシティユニット（RCU/WCU）の上限に達した際の挙動と、Auto Scaling設定を入れている場合のスケール追従性を検証する",
            "DynamoDBのテーブル設定画面でRCU/WCUを最大値に設定し、エラーが出ないことを確認してから、本番運用前に設定を元に戻す（コストがかかり、実際の挙動確認にならない）",
            "AWSサポートに連絡して、自社のテーブルが決してスロットリングしないように裏側で調整してもらう（そのような対応は存在しない）",
            "アプリケーション側でリトライ処理を実装しているため、DynamoDB側のテストは不要であると判断する（無限リトライによるシステムダウンのリスクを無視）"
        ],
        "answer": [
            "JMeter等で徐々に負荷を上げていき、読み込み/書き込みキャパシティユニット（RCU/WCU）の上限に達した際の挙動と、Auto Scaling設定を入れている場合のスケール追従性を検証する"
        ],
        "explanation": "【解説】\nDynamoDBのテストでは、設定したキャパシティを超えた時のスロットリング発生と、Auto Scalingが追いつくまでのタイムラグの挙動確認が重要です。",
        "tags": ["第1章", "AWS", "シナリオ", "K3"]
    }
]

# 5. 第2章 金融 (ch2_finance_vol116.json)
q2_fin = [
    {
        "id": "Q2-FIN-V116-01",
        "chapter": "第2章",
        "level": "K3",
        "category": "金融",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】与信審査ロジックのデシジョンテーブルテスト。\nクレジットカードの審査システムにおいて、「年収」「勤続年数」「過去の延滞歴」の3条件で合否が決まる。\n仕様の抜け漏れを防ぎ、ロジックを完全に網羅するためのテスト設計手法はどれか。",
        "options": [
            "年収が高い人のケースと低い人のケースだけを作成し、中間層はテストしない（境界値や複合条件の考慮不足）",
            "3つの条件の「Yes/No」あるいは境界値の全組み合わせを列挙した「デシジョンテーブル（決定表）」を作成し、それぞれの組み合わせに対する期待結果（合格/否決）を定義してテストする",
            "過去の審査データをAIに学習させ、AIが自動生成したテストケースのみを使用する（AIの学習データに含まれないレアケースを網羅できない）",
            "開発者が書いた `if` 文のネスト構造をそのまま図に書き起こし、それをもとにテストケースを作る（実装依存のテストになり、仕様の誤りを検出できない）"
        ],
        "answer": [
            "3つの条件の「Yes/No」あるいは境界値の全組み合わせを列挙した「デシジョンテーブル（決定表）」を作成し、それぞれの組み合わせに対する期待結果（合格/否決）を定義してテストする"
        ],
        "explanation": "【解説】\n複雑な条件分岐（ビジネスルール）のテストには、デシジョンテーブルが最適です。論理的な組み合わせを可視化することで、仕様の抜け漏れも発見しやすくなります。",
        "tags": ["第2章", "金融", "シナリオ", "K3"]
    }
]

# ==========================================
# ファイル生成 & Index更新処理
# ==========================================
files_content = {
    "ch3_general_vol116.json": q3_gen,
    "ch1_general_vol116.json": q1_gen,
    "ch2_general_vol116.json": q2_gen,
    "ch1_aws_vol116.json": q1_aws,
    "ch2_finance_vol116.json": q2_fin
}

def generate_and_update():
    # 1. ファイル生成
    new_entries = []
    
    print("--- ファイル生成開始 ---")
    for filename, content in files_content.items():
        file_path = os.path.join(OUTPUT_DIR, filename)
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(content, f, ensure_ascii=False, indent=2)
            print(f"作成: {filename}")
            
            # メタデータ抽出（Index用）
            first_q = content[0]
            entry = {
                "path": f"questions/{filename}", # アプリの仕様に合わせたパス
                "chapter": first_q.get("chapter", "不明"),
                "category": first_q.get("category", "不明"),
                "klevel": first_q.get("level", "K2"),
                "qCount": len(content)
            }
            new_entries.append(entry)
            
        except Exception as e:
            print(f"エラー作成中 {filename}: {e}")

    # 2. Index更新
    print("\n--- Index更新開始 ---")
    if not os.path.exists(INDEX_FILE):
        print(f"エラー: {INDEX_FILE} が見つかりません。")
        return

    try:
        with open(INDEX_FILE, 'r', encoding='utf-8') as f:
            index_data = json.load(f)
        
        existing_paths = {item.get("path") for item in index_data.get("chunks", [])}
        added_count = 0
        
        for entry in new_entries:
            if entry["path"] not in existing_paths:
                index_data["chunks"].append(entry)
                print(f"Index追加: {entry['path']}")
                added_count += 1
            else:
                print(f"Indexスキップ（登録済）: {entry['path']}")
        
        if added_count > 0:
            with open(INDEX_FILE, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, ensure_ascii=False, indent=2)
            print(f"Index保存完了: {added_count}件追加")
        else:
            print("Index更新なし")

    except Exception as e:
        print(f"Index更新エラー: {e}")

if __name__ == "__main__":
    generate_and_update()