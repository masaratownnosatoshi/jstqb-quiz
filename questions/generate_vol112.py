import json
import os

# 保存先ディレクトリ
OUTPUT_DIR = "."
INDEX_FILE = "index.json"

# ==========================================
# Vol.112 新規問題データ定義
# ==========================================

# 1. 第3章 一般 (ch3_general_vol112.json)
q3_gen = [
    {
        "id": "Q3-GEN-V112-01",
        "chapter": "第3章",
        "level": "K3",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】大規模アジャイル開発（LeSS/SAFe）における統合テスト戦略。\n複数のスクラムチームが並行してマイクロサービスの開発を行っている。\n各チームの「Done（完了）」は定義されているが、システム全体の統合時にインターフェース不整合が頻発している。\nこの問題を解決するためのスケーリング戦略として最も適切なものはどれか。",
        "options": [
            "各チームのベロシティを意図的に下げさせ、空いた時間で他チームのソースコードを互いにレビューし合うことで、コードレベルでの整合性を担保する（コミュニケーションコストが爆発する）",
            "「スクラム・オブ・スクラム（SoS）」を定期開催して依存関係を調整するとともに、CIパイプラインに「契約テスト（Consumer-Driven Contract Testing）」を導入して、APIの整合性を自動的に検証する",
            "統合テストは非常に複雑であるため、専任の「統合テストチーム」を新設し、すべての開発チームから成果物を引き取って、リリースの直前にまとめてテストを行う（フィードバックが遅れ、アジャイルの原則に反する）",
            "インターフェースの仕様を初期段階ですべて固定し（Freeze）、開発途中での変更を一切禁止することで、不整合の発生源を断つ（変化への対応ができなくなる）"
        ],
        "answer": [
            "「スクラム・オブ・スクラム（SoS）」を定期開催して依存関係を調整するとともに、CIパイプラインに「契約テスト（Consumer-Driven Contract Testing）」を導入して、APIの整合性を自動的に検証する"
        ],
        "explanation": "【解説】\n大規模アジャイルでは、チーム間の同期（SoS）と、自動化されたインターフェース検証（CDCテスト）の組み合わせが定石です。専門チームへの丸投げや仕様凍結はアンチパターンです。",
        "tags": ["第3章", "一般", "シナリオ", "K3"]
    }
]

# 2. 第1章 一般 (ch1_general_vol112.json)
q1_gen = [
    {
        "id": "Q1-GEN-V112-01",
        "chapter": "第1章",
        "level": "K3",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】テスト見積もり技法（ファンクションポイント法）。\n要件定義が完了した段階で、システムの規模に基づいたテスト工数を見積もりたい。\n画面数や帳票数といった「ユーザーから見た機能」の複雑さを基準に見積もる手法として、正しいアプローチはどれか。",
        "options": [
            "開発者が記述すると予想される「ソースコード行数（LOC）」を過去の経験から推測し、それに生産性係数を掛けてテスト工数を算出する（言語や書き方に依存するため精度が低い）",
            "外部入力（EI）、外部出力（EO）、外部照会（EQ）、内部論理ファイル（ILF）、外部インターフェースファイル（EIF）の5つの要素を数え、複雑度に応じた重み付けを行って「ファンクションポイント（FP）」を算出し、過去の実績値（FPあたりのテスト工数）を掛ける",
            "プロジェクトマネージャの「勘」と「経験」だけを頼りにし、過去の類似プロジェクトの工数をそのまま流用して、バッファを20%乗せる（根拠が属人的で説明責任を果たせない）",
            "「ユースケースポイント法」を使用するが、アクターやユースケースの複雑さは考慮せず、単にユースケースの個数だけに一律の単価を掛けて算出する（内容の軽重を無視している）"
        ],
        "answer": [
            "外部入力（EI）、外部出力（EO）、外部照会（EQ）、内部論理ファイル（ILF）、外部インターフェースファイル（EIF）の5つの要素を数え、複雑度に応じた重み付けを行って「ファンクションポイント（FP）」を算出し、過去の実績値（FPあたりのテスト工数）を掛ける"
        ],
        "explanation": "【解説】\nFP法（IFPUG法など）は、ユーザー視点の機能（5要素）に基づいて規模を測るため、技術選定に依存しない客観的な見積もりが可能です。",
        "tags": ["第1章", "一般", "シナリオ", "K3"]
    }
]

# 3. 第2章 一般 (ch2_general_vol112.json)
q2_gen = [
    {
        "id": "Q2-GEN-V112-01",
        "chapter": "第2章",
        "level": "K3",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】セキュリティテスト（認証に対する攻撃）。\nWebアプリのログイン機能に対して、「ブルートフォース攻撃（総当たり）」や「パスワードスプレー攻撃」への耐性を検証したい。\nアカウントロック機能の仕様確認として、最も適切かつ安全なテストケースはどれか。",
        "options": [
            "攻撃者のIPアドレスを永久にブロックする仕様を確認するため、社内のプロキシサーバーからのアクセスでわざと連続失敗させ、社内全員がアクセスできなくなることを確認する（DoS状態を自ら作り出す危険なテスト）",
            "特定のアカウントに対して、短時間に連続して（例: 5回）誤ったパスワードを入力し、アカウントが一時的にロックされること、および一定時間経過後（または管理者操作）に解除されることを確認する",
            "パスワードの複雑性要件（大文字・小文字・記号必須）を満たさないパスワードを設定しようとしたときに、エラーメッセージが表示されることだけを確認する（ロック機能のテストではない）",
            "実際に流出した数億件のパスワードリストを入手し、本番環境に対して辞書攻撃を仕掛けて、何件突破できるかを試す（法的に問題があり、サーバーへの過負荷リスクも高い）"
        ],
        "answer": [
            "特定のアカウントに対して、短時間に連続して（例: 5回）誤ったパスワードを入力し、アカウントが一時的にロックされること、および一定時間経過後（または管理者操作）に解除されることを確認する"
        ],
        "explanation": "【解説】\n総当たり攻撃対策の基本は「アカウントロック（スロットリング）」です。IPブロックはNAT環境で巻き添えBANのリスクがあるため、アカウント単位のロック挙動を確認するのが正解です。",
        "tags": ["第2章", "一般", "シナリオ", "K3"]
    }
]

# 4. 第1章 AWS (ch1_aws_vol112.json)
q1_aws = [
    {
        "id": "Q1-AWS-V112-01",
        "chapter": "第1章",
        "level": "K3",
        "category": "AWS",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】S3のコンプライアンス対応（WORM）。\n金融機関の監査ログ保存要件として、「一度保存したデータは、管理者であっても一定期間（7年間）は絶対に削除・変更できてはならない（WORM: Write Once Read Many）」がある。\nこの要件を満たす設定と、その検証方法はどれか。",
        "options": [
            "S3バケットポリシーで「s3:DeleteObject」アクションを全ユーザー（root含む）に対してDeny設定し、実際に削除コマンドを実行してエラーになることを確認する（rootユーザーならポリシー解除できてしまう）",
            "S3オブジェクトロックを「コンプライアンスモード」で有効化し、保持期間を設定した上で、rootユーザーであっても削除や上書き、保持期間の短縮が不可能であることを確認する",
            "S3のバージョニング機能を有効にし、削除された場合は過去バージョンから復元できる手順を整備して、運用訓練を行う（削除自体はできてしまうため、WORM要件を満たさない）",
            "MFA Delete（多要素認証による削除）を有効化し、MFAデバイスを持っていない担当者が削除できないことを確認する（MFAを持っていれば削除できるため、絶対的な禁止ではない）"
        ],
        "answer": [
            "S3オブジェクトロックを「コンプライアンスモード」で有効化し、保持期間を設定した上で、rootユーザーであっても削除や上書き、保持期間の短縮が不可能であることを確認する"
        ],
        "explanation": "【解説】\n法的保存要件（WORM）には「S3 Object Lock」の「Compliance Mode」が唯一の解です。Governance Modeやバケットポリシーでは、特権ユーザーによる削除を防げません。",
        "tags": ["第1章", "AWS", "シナリオ", "K3"]
    }
]

# 5. 第2章 金融 (ch2_finance_vol112.json)
q2_fin = [
    {
        "id": "Q2-FIN-V112-01",
        "chapter": "第2章",
        "level": "K4",
        "category": "金融",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【分析】同時実行制御（排他制御）のテスト。\n銀行口座の残高更新処理において、「複数のATMから同時に引き出し操作が行われた」場合の整合性を検証したい。\nデータベースの「レースコンディション（競合）」を防ぐための適切なロック機構の検証方法はどれか。",
        "options": [
            "2つのトランザクションがほぼ同時に開始され、片方が参照してから更新するまでの間に、もう片方が割り込んで更新を完了させるシナリオを作成し、「悲観的ロック（SELECT FOR UPDATE）」等により後続処理が待機（ブロック）されることを確認する",
            "トランザクションを直列（順番）に実行し、Aさんが引き出した後にBさんが引き出すという正常系シナリオだけを確認する（競合状態が発生しないためテストにならない）",
            "「楽観的ロック（バージョンカラム使用）」を採用しているシステムにおいて、競合発生時に後続のトランザクションが強制的に上書き保存し、データ不整合が起きないことを確認する（楽観ロックでは上書きではなくエラーになるべき）",
            "データベースの分離レベル（Isolation Level）を「Read Uncommitted」に設定し、コミット前のデータが読み取れる状態でテストを行う（整合性が保証されない最低レベルの設定）"
        ],
        "answer": [
            "2つのトランザクションがほぼ同時に開始され、片方が参照してから更新するまでの間に、もう片方が割り込んで更新を完了させるシナリオを作成し、「悲観的ロック（SELECT FOR UPDATE）」等により後続処理が待機（ブロック）されることを確認する"
        ],
        "explanation": "【解説】\n残高更新の競合テストでは、意図的にタイミングを重ねて「ロック待ち（Wait）」または「リトライエラー」が発生し、データの整合性（ACID）が守られるかを確認する必要があります。",
        "tags": ["第2章", "金融", "シナリオ", "K4"]
    }
]

# ==========================================
# ファイル生成 & Index更新処理
# ==========================================
files_content = {
    "ch3_general_vol112.json": q3_gen,
    "ch1_general_vol112.json": q1_gen,
    "ch2_general_vol112.json": q2_gen,
    "ch1_aws_vol112.json": q1_aws,
    "ch2_finance_vol112.json": q2_fin
}

def generate_and_update():
    # 1. ファイル生成
    new_entries = []
    
    print("--- ファイル生成開始 ---")
    for filename, content in files_content.items():
        file_path = os.path.join(OUTPUT_DIR, filename)
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(content, f, ensure_ascii=False, indent=2)
            print(f"作成: {filename}")
            
            # メタデータ抽出（Index用）
            first_q = content[0]
            entry = {
                "path": f"questions/{filename}", # アプリの仕様に合わせたパス
                "chapter": first_q.get("chapter", "不明"),
                "category": first_q.get("category", "不明"),
                "klevel": first_q.get("level", "K2"),
                "qCount": len(content)
            }
            new_entries.append(entry)
            
        except Exception as e:
            print(f"エラー作成中 {filename}: {e}")

    # 2. Index更新
    print("\n--- Index更新開始 ---")
    if not os.path.exists(INDEX_FILE):
        print(f"エラー: {INDEX_FILE} が見つかりません。")
        return

    try:
        with open(INDEX_FILE, 'r', encoding='utf-8') as f:
            index_data = json.load(f)
        
        existing_paths = {item.get("path") for item in index_data.get("chunks", [])}
        added_count = 0
        
        for entry in new_entries:
            if entry["path"] not in existing_paths:
                index_data["chunks"].append(entry)
                print(f"Index追加: {entry['path']}")
                added_count += 1
            else:
                print(f"Indexスキップ（登録済）: {entry['path']}")
        
        if added_count > 0:
            with open(INDEX_FILE, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, ensure_ascii=False, indent=2)
            print(f"Index保存完了: {added_count}件追加")
        else:
            print("Index更新なし")

    except Exception as e:
        print(f"Index更新エラー: {e}")

if __name__ == "__main__":
    generate_and_update()