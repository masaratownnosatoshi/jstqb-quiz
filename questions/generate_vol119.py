import json
import os

# 保存先ディレクトリ
OUTPUT_DIR = "."
INDEX_FILE = "index.json"

# ==========================================
# Vol.119 新規問題データ定義
# ==========================================

# 1. 第3章 一般 (ch3_general_vol119.json)
q3_gen = [
    {
        "id": "Q3-GEN-V119-01",
        "chapter": "第3章",
        "level": "K3",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】GQM（Goal-Question-Metric）法によるメトリクス定義。\n組織の課題として「テストの効率性が低いのではないか」という懸念がある。\nGQM法を用いて、この課題を定量的に測定するためのアプローチとして正しい流れはどれか。",
        "options": [
            "まず手元にあるツールで収集可能なデータを全てリストアップし、その中からグラフにできそうなものを選んで「効率性指標」と名付ける（データありきの逆算アプローチ）",
            "「テスト効率を向上させる」というゴール（Goal）を設定し、それを達成しているか判断するための質問（Question）を定義し、その質問に答えるために必要なデータ（Metric）を特定する",
            "他社の事例や業界標準のメトリクス（欠陥密度など）をそのままコピーして採用し、自社のコンテキストに合っているかは考慮せずに運用を開始する（形骸化のリスク）",
            "メトリクスは現場の負担になるため、定量的な測定は行わず、マネージャの主観的な満足度アンケートだけで効率性を評価することにする（客観性の欠如）"
        ],
        "answer": [
            "「テスト効率を向上させる」というゴール（Goal）を設定し、それを達成しているか判断するための質問（Question）を定義し、その質問に答えるために必要なデータ（Metric）を特定する"
        ],
        "explanation": "【解説】\nGQM法の真髄はトップダウンのアプローチ（ゴール→質問→メトリクス）です。手段（収集可能なデータ）から入ると、無意味な数字遊びに陥ります。",
        "tags": ["第3章", "一般", "シナリオ", "K3"]
    }
]

# 2. 第1章 一般 (ch1_general_vol119.json)
q1_gen = [
    {
        "id": "Q1-GEN-V119-01",
        "chapter": "第1章",
        "level": "K3",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】テストデータの匿名化（マスキング）と特異値。\n本番データを用いてパフォーマンステストを行いたいが、個人情報保護のためにデータをマスキングする必要がある。\nしかし、単純な置換（すべての氏名を「テスト」にする等）を行うと、データベースのインデックス効率や分散が変わってしまい、正しい性能測定ができなくなるリスクがある。\nこの問題への対処法はどれか。",
        "options": [
            "個人情報保護よりも正確な性能測定が優先されるため、特例申請を行って生の本番データをそのままテスト環境で使用する（コンプライアンス違反のリスク大）",
            "カーディナリティ（値のばらつき）や分布傾向を維持したまま置換する「仮名化（Pseudonymization）」や「合成データ生成」技術を使用し、統計的な特性を本番に近づける",
            "性能テストの結果はデータの中身には依存しないため、すべてのカラムを空文字またはNULLにしてデータ量を軽量化してからテストする（インデックスが効かなくなり結果が歪む）",
            "本番データの件数だけを合わせ、中身はすべて「0」で埋めたダミーデータを作成してテストする（実際のデータ分布とかけ離れており、キャッシュヒット率などが変わる）"
        ],
        "answer": [
            "カーディナリティ（値のばらつき）や分布傾向を維持したまま置換する「仮名化（Pseudonymization）」や「合成データ生成」技術を使用し、統計的な特性を本番に近づける"
        ],
        "explanation": "【解説】\n性能テスト用のデータは、単なる量だけでなく「分布（カーディナリティ）」が重要です。単純な一律置換ではDBの実行計画が変わり、テストになりません。",
        "tags": ["第1章", "一般", "シナリオ", "K3"]
    }
]

# 3. 第2章 一般 (ch2_general_vol119.json)
q2_gen = [
    {
        "id": "Q2-GEN-V119-01",
        "chapter": "第2章",
        "level": "K3",
        "category": "一般",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】ユーザビリティ評価（ヒューリスティック評価）。\nUIデザインの専門家ではないテスト担当者が、ヤコブ・ニールセンの「10のユーザビリティヒューリスティクス」に基づいて画面の評価を行うことになった。\n評価の進め方として、ヒューリスティック評価の原則に合致するものはどれか。",
        "options": [
            "実際のユーザーを集めて操作してもらい、どこでつまずいたかを観察して記録する（これは「ユーザーテスト」であり、ヒューリスティック評価ではない）",
            "評価者（テスター）がガイドライン（10の原則）を基準に画面を点検し、「システムの状態が可視化されているか」や「ユーザーの言葉を使っているか」といった観点で問題点を指摘する",
            "画面上のボタン配置や配色が、評価者の個人的な好みやセンスに合っているかどうかを主観的に判定し、気に入らない点をリストアップする（原則に基づかない単なる感想）",
            "アクセス解析ツールを導入し、ユーザーの滞在時間や離脱率を定量的に測定して、数値が悪いページを特定する（これは定量的評価であり、専門家による定性的評価ではない）"
        ],
        "answer": [
            "評価者（テスター）がガイドライン（10の原則）を基準に画面を点検し、「システムの状態が可視化されているか」や「ユーザーの言葉を使っているか」といった観点で問題点を指摘する"
        ],
        "explanation": "【解説】\nヒューリスティック評価は、専門家（またはレビュアー）が既知の原則（ヒューリスティクス）に基づいて行う「専門家レビュー」の一種です。ユーザーテストとは異なります。",
        "tags": ["第2章", "一般", "シナリオ", "K3"]
    }
]

# 4. 第1章 AWS (ch1_aws_vol119.json)
q1_aws = [
    {
        "id": "Q1-AWS-V119-01",
        "chapter": "第1章",
        "level": "K3",
        "category": "AWS",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【適用】Amazon EFSのパフォーマンスモード選択とテスト。\n大量の小規模ファイル（数百万件のログファイルなど）を並列処理するビッグデータ分析基盤において、EFSのパフォーマンスが出ないという課題がある。\n適切な設定変更と、その効果を確認するための検証方法はどれか。",
        "options": [
            "パフォーマンスモードをデフォルトの「汎用（General Purpose）」から「最大I/O（Max I/O）」に変更し、レイテンシ（遅延）が多少悪化しても、並列アクセス時のスループット（合計転送量）が向上することを確認する",
            "EFSの使用をやめて、単一のEBSボリュームを複数のインスタンスから同時にマウントする構成に変更する（EBSのMulti-Attachは制約が多く、通常ファイルシステムとしては機能しない）",
            "ファイルサイズが小さいことが原因であるため、すべてのファイルを1つの巨大なzipファイルに圧縮してから保存するようにアプリを改修する（ランダムアクセスができなくなる）",
            "スループットモードを「バースト」から「プロビジョニング」に変更し、使用量に関わらず固定の帯域を確保するだけで、Max I/Oへの変更は検討しない（ファイル操作自体のIOPS限界には対処できない）"
        ],
        "answer": [
            "パフォーマンスモードをデフォルトの「汎用（General Purpose）」から「最大I/O（Max I/O）」に変更し、レイテンシ（遅延）が多少悪化しても、並列アクセス時のスループット（合計転送量）が向上することを確認する"
        ],
        "explanation": "【解説】\n大量の並列アクセスが必要な場合、EFSは「Max I/O」モードが推奨されます。ただし、ファイルごとのレイテンシはGeneral Purposeより高くなるため、そのトレードオフをテストで確認します。",
        "tags": ["第1章", "AWS", "シナリオ", "K3"]
    }
]

# 5. 第2章 金融 (ch2_finance_vol119.json)
q2_fin = [
    {
        "id": "Q2-FIN-V119-01",
        "chapter": "第2章",
        "level": "K4",
        "category": "金融",
        "style": "シナリオ",
        "type": "単一選択",
        "question": "【分析】会計システムの仕訳生成テスト。\n業務システム（販売管理）から会計システムへ連携する「自動仕訳データ」の整合性を検証したい。\n「貸借平均の原理」に基づき、必ず検証しなければならない整合性チェックはどれか。",
        "options": [
            "借方（Debit）と貸方（Credit）の科目が同じであること（貸借が同じなら仕訳の意味がない）",
            "1つの取引（Transaction）内で生成される複数の仕訳行において、借方金額の合計と貸方金額の合計が必ず一致しており、差額がゼロになること",
            "すべての金額がプラスの値であり、マイナス金額の仕訳は絶対に存在しないこと（訂正仕訳や赤黒処理でマイナスはあり得る）",
            "勘定科目のコードが昇順にソートされていること（システム的な都合であり、会計上の整合性要件ではない）"
        ],
        "answer": [
            "1つの取引（Transaction）内で生成される複数の仕訳行において、借方金額の合計と貸方金額の合計が必ず一致しており、差額がゼロになること"
        ],
        "explanation": "【解説】\n複式簿記の絶対ルールは「貸借一致（Balance）」です。どんなに複雑な複合仕訳であっても、借方合計と貸方合計は必ず一致しなければなりません。",
        "tags": ["第2章", "金融", "シナリオ", "K4"]
    }
]

# ==========================================
# ファイル生成 & Index更新処理
# ==========================================
files_content = {
    "ch3_general_vol119.json": q3_gen,
    "ch1_general_vol119.json": q1_gen,
    "ch2_general_vol119.json": q2_gen,
    "ch1_aws_vol119.json": q1_aws,
    "ch2_finance_vol119.json": q2_fin
}

def generate_and_update():
    # 1. ファイル生成
    new_entries = []
    
    print("--- ファイル生成開始 ---")
    for filename, content in files_content.items():
        file_path = os.path.join(OUTPUT_DIR, filename)
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(content, f, ensure_ascii=False, indent=2)
            print(f"作成: {filename}")
            
            # メタデータ抽出（Index用）
            first_q = content[0]
            entry = {
                "path": f"questions/{filename}", # アプリの仕様に合わせたパス
                "chapter": first_q.get("chapter", "不明"),
                "category": first_q.get("category", "不明"),
                "klevel": first_q.get("level", "K2"),
                "qCount": len(content)
            }
            new_entries.append(entry)
            
        except Exception as e:
            print(f"エラー作成中 {filename}: {e}")

    # 2. Index更新
    print("\n--- Index更新開始 ---")
    if not os.path.exists(INDEX_FILE):
        print(f"エラー: {INDEX_FILE} が見つかりません。")
        return

    try:
        with open(INDEX_FILE, 'r', encoding='utf-8') as f:
            index_data = json.load(f)
        
        existing_paths = {item.get("path") for item in index_data.get("chunks", [])}
        added_count = 0
        
        for entry in new_entries:
            if entry["path"] not in existing_paths:
                index_data["chunks"].append(entry)
                print(f"Index追加: {entry['path']}")
                added_count += 1
            else:
                print(f"Indexスキップ（登録済）: {entry['path']}")
        
        if added_count > 0:
            with open(INDEX_FILE, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, ensure_ascii=False, indent=2)
            print(f"Index保存完了: {added_count}件追加")
        else:
            print("Index更新なし")

    except Exception as e:
        print(f"Index更新エラー: {e}")

if __name__ == "__main__":
    generate_and_update()